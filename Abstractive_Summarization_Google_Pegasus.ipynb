{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstractive Summarization Google Pegasus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Dependencies"
      ],
      "metadata": {
        "id": "iPfhOHmAVwLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qabKhG4_Vb1W"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "26SIuYvaVdvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "Gm5VPUq7Vfsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import and Load Model"
      ],
      "metadata": {
        "id": "NprRvwNTVxwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies from transformers\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
      ],
      "metadata": {
        "id": "r3Rq7KtIVlg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer \n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "metadata": {
        "id": "5WH0C51LVoJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model \n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "metadata": {
        "id": "iSVt69FmV5eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform Abstractive Summarization"
      ],
      "metadata": {
        "id": "qHQeHOsXWBov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Python is an interpreted high-level general-purpose programming language. Its design philosophy emphasizes code readability with its use of significant indentation. Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[30]\n",
        "\n",
        "Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[31]\n",
        "\n",
        "Guido van Rossum began working on Python in the late 1980s, as a successor to the ABC programming language, and first released it in 1991 as Python 0.9.0.[32] Python 2.0 was released in 2000 and introduced new features, such as list comprehensions and a garbage collection system using reference counting. Python 3.0 was released in 2008 and was a major revision of the language that is not completely backward-compatible. Python 2 was discontinued with version 2.7.18 in 2020.[33]\n",
        "\n",
        "Python consistently ranks as one of the most popular programming languages.[34][35][36][37]\"\"\""
      ],
      "metadata": {
        "id": "dH3UauPvWC48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokens - number representation of our text\n",
        "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "6JtD_fJ1WLVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input tokens\n",
        "tokens"
      ],
      "metadata": {
        "id": "U_8LmGlsWNjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize \n",
        "summary = model.generate(**tokens)"
      ],
      "metadata": {
        "id": "Y6ysI0pMWTL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output summary tokens\n",
        "summary[0]"
      ],
      "metadata": {
        "id": "y-KZ_W7tWWgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode summary\n",
        "tokenizer.decode(summary[0])"
      ],
      "metadata": {
        "id": "XJ9FEOqAWZSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}